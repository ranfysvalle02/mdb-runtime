name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  release:
    types: [published]
  workflow_dispatch:
    inputs:
      run_integration_tests:
        description: 'Run integration tests'
        required: false
        default: 'true'
        type: boolean
      publish_to_pypi:
        description: 'Publish to PyPI'
        required: false
        default: 'false'
        type: boolean
      skip_cache:
        description: 'Skip dependency cache (force fresh install)'
        required: false
        default: 'false'
        type: boolean

# Cancel outdated workflow runs to save CI minutes
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}-${{ github.event.pull_request.number || github.sha }}
  cancel-in-progress: true

env:
  PYTHON_VERSION_DEFAULT: '3.11'
  PIP_CACHE_DIR: ~/.cache/pip
  RUFF_CACHE_DIR: ~/.cache/ruff

jobs:
  # Detect which paths changed to optimize job execution
  detect-changes:
    name: Detect Changes
    runs-on: ubuntu-latest
    outputs:
      code: ${{ steps.filter.outputs.code }}
      tests: ${{ steps.filter.outputs.tests }}
      docs: ${{ steps.filter.outputs.docs }}
      python: ${{ steps.filter.outputs.python }}
      ci: ${{ steps.filter.outputs.ci }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for better change detection

      - name: Detect changes
        uses: dorny/paths-filter@v3
        id: filter
        with:
          filters: |
            code:
              - 'mdb_engine/**'
              - 'tests/**'
              - 'scripts/**'
              - 'pyproject.toml'
              - 'setup.py'
              - 'Makefile'
              - '.flake8'
              - '.semgrep.yml'
            tests:
              - 'mdb_engine/**'
              - 'tests/**'
              - 'pyproject.toml'
              - 'setup.py'
            docs:
              - 'docs/**'
              - '*.md'
              - 'examples/**'
            python:
              - 'pyproject.toml'
              - 'setup.py'
              - '.python-version'
            ci:
              - '.github/workflows/**'

  # Code quality checks (formatting, linting, security)
  # Run once per PR/push, not per Python version for efficiency
  code-quality:
    name: Code Quality
    runs-on: ubuntu-latest
    needs: detect-changes
    if: |
      github.event_name == 'workflow_dispatch' ||
      github.event_name == 'push' ||
      github.event_name == 'pull_request' ||
      needs.detect-changes.outputs.code == 'true'
    timeout-minutes: 10
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION_DEFAULT }}
          cache: 'pip'
          cache-dependency-path: |
            pyproject.toml
            setup.py

      - name: Cache Ruff
        if: github.event.inputs.skip_cache != 'true'
        uses: actions/cache@v4
        with:
          path: ${{ env.RUFF_CACHE_DIR }}
          key: ruff-${{ runner.os }}-${{ hashFiles('pyproject.toml') }}
          restore-keys: |
            ruff-${{ runner.os }}-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -e ".[dev]"

      - name: Check code formatting
        run: |
          echo "::group::Formatting Check"
          ruff format --check mdb_engine tests scripts
          echo "::endgroup::"
        continue-on-error: false

      - name: Run linting (CI mode)
        run: |
          echo "::group::Linting"
          make lint-ci
          echo "::endgroup::"

      - name: Run Ruff type checking
        run: |
          echo "::group::Type Checking"
          ruff check --select TYP mdb_engine tests scripts || echo "âš ï¸ Type checking found issues (non-blocking)"
          echo "::endgroup::"

      - name: Check for dependency vulnerabilities
        run: |
          echo "::group::Security Scan"
          pip install safety || true
          safety check --file requirements.txt 2>/dev/null || safety check 2>/dev/null || echo "âš ï¸ Safety check skipped"
          echo "::endgroup::"

      - name: Run Semgrep security scan
        run: |
          echo "::group::Semgrep Security Scan"
          semgrep scan --config .semgrep.yml --error --quiet mdb_engine/ || echo "âš ï¸ Semgrep scan completed with findings"
          echo "::endgroup::"

  # Unit tests across multiple Python versions
  test-unit:
    name: Unit Tests (Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest
    needs: detect-changes
    if: |
      github.event_name == 'workflow_dispatch' ||
      github.event_name == 'push' ||
      github.event_name == 'pull_request' ||
      needs.detect-changes.outputs.tests == 'true'
    timeout-minutes: 20
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.10", "3.11", "3.12"]
        include:
          - python-version: "3.10"
            is-latest: false
          - python-version: "3.11"
            is-latest: false
          - python-version: "3.12"
            is-latest: true
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'
          cache-dependency-path: |
            pyproject.toml
            setup.py

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -e ".[test,dev]"
          pip install pytest-xdist

      - name: Cache pytest cache
        if: github.event.inputs.skip_cache != 'true'
        uses: actions/cache@v4
        with:
          path: .pytest_cache
          key: pytest-${{ runner.os }}-${{ matrix.python-version }}-${{ hashFiles('**/test_*.py', '**/conftest.py') }}
          restore-keys: |
            pytest-${{ runner.os }}-${{ matrix.python-version }}-

      - name: Run unit tests with coverage
        # Skip older Python versions on PRs for faster feedback (only run 3.12)
        if: github.event_name != 'pull_request' || matrix.python-version == '3.12'
        run: |
          echo "::group::Unit Tests (Python ${{ matrix.python-version }})"
          pytest tests/unit -v \
            --cov=mdb_engine/core \
            --cov=mdb_engine/database \
            --cov-report=term-missing \
            --cov-report=xml:coverage-${{ matrix.python-version }}.xml \
            --cov-report=html:htmlcov-${{ matrix.python-version }} \
            --cov-fail-under=70 \
            --junit-xml=junit-unit-${{ matrix.python-version }}.xml \
            -m "not integration" \
            -n auto \
            --maxfail=5 \
            --tb=short
          echo "::endgroup::"

      - name: Test Summary
        if: always()
        run: |
          echo "## Test Results for Python ${{ matrix.python-version }}" >> $GITHUB_STEP_SUMMARY
          if [ -f junit-unit-${{ matrix.python-version }}.xml ]; then
            echo "âœ… Test results generated" >> $GITHUB_STEP_SUMMARY
          else
            echo "âš ï¸ Test results file not found" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload coverage reports
        if: matrix.is-latest == true
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: |
            htmlcov-${{ matrix.python-version }}/
            coverage-${{ matrix.python-version }}.xml
          retention-days: 30
          if-no-files-found: warn

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-py${{ matrix.python-version }}
          path: junit-unit-${{ matrix.python-version }}.xml
          retention-days: 7
          if-no-files-found: ignore

      - name: Comment PR with test results
        if: github.event_name == 'pull_request' && matrix.is-latest == true && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = 'junit-unit-${{ matrix.python-version }}.xml';
            if (fs.existsSync(path)) {
              const xml = fs.readFileSync(path, 'utf8');
              const tests = xml.match(/tests="(\d+)"/)?.[1] || '0';
              const failures = xml.match(/failures="(\d+)"/)?.[1] || '0';
              const errors = xml.match(/errors="(\d+)"/)?.[1] || '0';
              
              const body = `## ðŸ§ª Test Results (Python ${{ matrix.python-version }})
              
              - âœ… Tests: ${tests}
              - âŒ Failures: ${failures}
              - âš ï¸ Errors: ${errors}
              
              [View full results](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})`;
              
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: body
              });
            }

  # Integration tests (run on latest Python version only, requires Docker)
  test-integration:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [code-quality, detect-changes]
    if: |
      (github.event_name == 'workflow_dispatch' && (github.event.inputs.run_integration_tests == 'true' || github.event.inputs.run_integration_tests == '')) ||
      (github.ref == 'refs/heads/main' && needs.detect-changes.outputs.tests == 'true') ||
      (github.event_name == 'pull_request' && needs.detect-changes.outputs.tests == 'true')
    timeout-minutes: 30
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION_DEFAULT }}
          cache: 'pip'
          cache-dependency-path: |
            pyproject.toml
            setup.py

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -e ".[test,dev]"

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Verify Docker is available
        run: |
          docker --version
          docker info

      - name: Run integration tests
        env:
          SKIP_DOCKER_CHECK: 1
        run: |
          echo "::group::Integration Tests"
          pytest tests/integration -v -m integration \
            --junit-xml=junit-integration.xml \
            --maxfail=3 \
            --tb=short
          echo "::endgroup::"

      - name: Integration Test Summary
        if: always()
        run: |
          echo "## Integration Test Results" >> $GITHUB_STEP_SUMMARY
          if [ -f junit-integration.xml ]; then
            echo "âœ… Integration tests completed" >> $GITHUB_STEP_SUMMARY
          else
            echo "âš ï¸ Integration test results file not found" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload integration test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: integration-test-results
          path: |
            junit-integration.xml
            .pytest_cache/
          retention-days: 7
          if-no-files-found: ignore

  # Publish job (only runs on release or manual dispatch)
  publish:
    name: Publish to PyPI
    needs: [code-quality, test-unit]
    runs-on: ubuntu-latest
    if: |
      (github.event_name == 'workflow_dispatch' && github.event.inputs.publish_to_pypi == 'true') ||
      (github.event_name == 'release' && github.event.action == 'published') ||
      (github.event_name == 'push' && startsWith(github.ref, 'refs/tags/v'))
    timeout-minutes: 15
    permissions:
      contents: read
      id-token: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION_DEFAULT }}
          cache: 'pip'
          cache-dependency-path: |
            pyproject.toml
            setup.py

      - name: Install build tools
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install build twine

      - name: Verify PyPI token from GitHub secrets
        run: |
          if [ -z "${{ secrets.PYPI_API_TOKEN }}" ]; then
            echo "::error::PYPI_API_TOKEN secret is not configured in GitHub repository secrets"
            echo ""
            echo "To configure:"
            echo "1. Go to: Settings â†’ Secrets and variables â†’ Actions"
            echo "2. Click 'New repository secret'"
            echo "3. Name: PYPI_API_TOKEN"
            echo "4. Value: Your PyPI API token from https://pypi.org/manage/account/token/"
            echo "5. Click 'Add secret'"
            exit 1
          fi
          echo "âœ… PyPI token is configured from GitHub repository secrets"

      - name: Build package
        run: |
          echo "::group::Building Package"
          python -m build
          echo "::endgroup::"

      - name: Check package
        run: |
          echo "::group::Package Validation"
          python -m twine check dist/*
          echo "::endgroup::"

      - name: Show package info
        run: |
          echo "## ðŸ“¦ Package Information" >> $GITHUB_STEP_SUMMARY
          echo "**Built packages:**" >> $GITHUB_STEP_SUMMARY
          ls -lh dist/ | sed 's/^/  - /' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Package version:**" >> $GITHUB_STEP_SUMMARY
          grep "^version" pyproject.toml setup.py | head -1 >> $GITHUB_STEP_SUMMARY

      - name: Publish to PyPI using GitHub secret
        env:
          TWINE_USERNAME: __token__
          TWINE_PASSWORD: ${{ secrets.PYPI_API_TOKEN }}
        run: |
          echo "::group::Publishing to PyPI"
          echo "Using PyPI API token from GitHub repository secrets (PYPI_API_TOKEN)"
          python -m twine upload dist/* --verbose --non-interactive
          echo "::endgroup::"

      - name: Publish Summary
        if: success()
        run: |
          echo "## ðŸ“¦ Package Published Successfully" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Package built and published to PyPI" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Install with:** \`pip install mdb-engine\`" >> $GITHUB_STEP_SUMMARY
          echo "**View on PyPI:** https://pypi.org/project/mdb-engine/" >> $GITHUB_STEP_SUMMARY

      - name: Publish Error Summary
        if: failure()
        run: |
          echo "## âŒ PyPI Publish Failed" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Common issues:**" >> $GITHUB_STEP_SUMMARY
          echo "1. **Missing PYPI_API_TOKEN secret**: Configure in Settings â†’ Secrets â†’ Actions" >> $GITHUB_STEP_SUMMARY
          echo "2. **Invalid token**: Get a new token from https://pypi.org/manage/account/token/" >> $GITHUB_STEP_SUMMARY
          echo "3. **Version already exists**: Bump version in pyproject.toml and setup.py" >> $GITHUB_STEP_SUMMARY
          echo "4. **Package name conflict**: Check https://pypi.org/project/mdb-engine/" >> $GITHUB_STEP_SUMMARY
          echo "5. **Network/API issues**: Check PyPI status at https://status.python.org/" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Note**: The workflow uses the \`PYPI_API_TOKEN\` secret from GitHub repository secrets." >> $GITHUB_STEP_SUMMARY
          echo "Check the logs above for specific error details." >> $GITHUB_STEP_SUMMARY
