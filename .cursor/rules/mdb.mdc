---
description: Comprehensive rules and best practices for MongoDB projects, focusing on Driver Selection, Atlas Search/Vector Indexing, and Aggregation Pipeline optimization.
globs: **/*.py, **/*.js, **/*.ts, **/*.go, **/*.java
---

# MongoDB & Atlas Search Implementation Guidelines

## 1. Architecture & Driver Selection

**Context:** The choice of database driver must strictly match the application's I/O architecture. Mixing blocking and non-blocking patterns causes severe performance degradation or deadlocks.

* **Rule (Async Contexts):** When working in asynchronous frameworks (e.g., FastAPI, Node.js, Go/Goroutines), you **MUST** use asynchronous drivers (e.g., `motor`, native Node driver).
    * *Constraint:* Never use synchronous/blocking driver calls inside an async function. This blocks the main event loop.
* **Rule (Sync Contexts):** In synchronous scripts, CLI tools, or legacy WSGI apps, prefer standard synchronous drivers (e.g., `pymongo`) for simplicity.
* **Pattern:** Wrap database utilities in the native paradigm of the framework.

```python
# ✅ Correct: Async usage (FastAPI/Tornado)
async def get_user_async(collection, user_id):
    return await collection.find_one({"user_id": user_id})

# ✅ Correct: Sync usage (CLI/Scripts)
def get_user_sync(collection, user_id):
    return collection.find_one({"user_id": user_id})
````

## 2. Connection Pool Management & Monitoring

**Context:** MongoDB drivers use connection pooling to efficiently manage database connections. Proper pool configuration and monitoring is critical for production applications to avoid connection exhaustion, deadlocks, and performance degradation.

### A. Pool Configuration Best Practices

* **Rule:** Always configure `maxPoolSize` explicitly based on your application's concurrency model.
    * *Async Apps (FastAPI/Motor):* Default 100 is usually sufficient, but scale up if you have high concurrency (many concurrent requests).
    * *Sync Apps (PyMongo):* Lower values (10-50) are often sufficient since threads are more expensive.
* **Rule:** Set `minPoolSize` to maintain a baseline of ready connections (reduces connection establishment latency).
* **Rule:** Configure `maxIdleTimeMS` to close idle connections and free resources (default: 60000ms).
* **Pattern:** Use connection string parameters or client options for configuration.

```python
from motor.motor_asyncio import AsyncIOMotorClient

# ✅ Correct: Explicit pool configuration
client = AsyncIOMotorClient(
    mongo_uri,
    maxPoolSize=100,        # Maximum concurrent connections
    minPoolSize=10,         # Minimum connections to maintain
    maxIdleTimeMS=30000,   # Close idle connections after 30s
    serverSelectionTimeoutMS=5000,  # Fail fast if server unavailable
    retryWrites=True,
    retryReads=True,
    appname="MyApp"        # Identify your app in server logs
)
```

### B. Monitoring Pool Metrics

* **Rule:** Use MongoDB's `serverStatus` command for accurate connection pool metrics. Do NOT rely solely on driver-internal attributes which may be unavailable or inconsistent.
* **Rule:** Monitor these key metrics:
    * `current_connections`: Active connections in use
    * `available_connections`: Connections available in pool
    * `total_connections_created`: Lifetime connection count
    * `pool_usage_percent`: (current / max) * 100
* **Pattern:** Implement a health check that queries `serverStatus` and calculates pool usage.

```python
async def get_pool_metrics(client: AsyncIOMotorClient) -> Dict[str, Any]:
    """
    Get accurate connection pool metrics from MongoDB serverStatus.
    This is more reliable than driver-internal attributes.
    """
    try:
        server_status = await client.admin.command("serverStatus")
        connections = server_status.get("connections", {})
        
        # Get pool config from client options
        max_pool_size = getattr(client.options, 'maxPoolSize', None) or 100
        
        current = connections.get("current", 0)
        available = connections.get("available", 0)
        total_created = connections.get("totalCreated", 0)
        
        usage_percent = (current / max_pool_size * 100) if max_pool_size else None
        
        return {
            "status": "connected",
            "max_pool_size": max_pool_size,
            "current_connections": current,
            "available_connections": available,
            "total_connections_created": total_created,
            "pool_usage_percent": round(usage_percent, 2) if usage_percent else None,
        }
    except Exception as e:
        return {
            "status": "error",
            "error": str(e)
        }
```

### C. Multi-Client Architecture (Runtime Engines)

* **Rule:** When using a runtime engine or framework that creates its own MongoDB client (separate from a shared connection manager), you MUST register that client for monitoring.
* **Rule:** Health checks should gracefully handle cases where detailed metrics aren't available. Use `UNKNOWN` status for missing metrics, not `UNHEALTHY`.
* **Pattern:** Implement a client registry pattern for tracking all clients in use.

```python
# ✅ Correct: Register engine's client for monitoring
_registered_clients: list = []

def register_client_for_metrics(client: AsyncIOMotorClient) -> None:
    """Register a client for pool metrics monitoring."""
    global _registered_clients
    if client not in _registered_clients:
        _registered_clients.append(client)

async def get_pool_metrics(client: Optional[AsyncIOMotorClient] = None):
    """Get metrics from specific client, shared client, or registered clients."""
    if client is not None:
        return await _get_client_pool_metrics(client)
    
    # Try shared client first
    if _shared_client is not None:
        return await _get_client_pool_metrics(_shared_client)
    
    # Try registered clients (e.g., RuntimeEngine's dedicated client)
    for registered_client in _registered_clients:
        try:
            if hasattr(registered_client, '_topology') and registered_client._topology:
                return await _get_client_pool_metrics(registered_client)
        except Exception:
            continue
    
    # No client available - return UNKNOWN, not error
    return {
        "status": "no_client",
        "note": "No MongoDB client available for metrics"
    }
```

### D. Health Check Implementation

* **Rule:** Health checks should distinguish between critical failures and missing metrics:
    * `HEALTHY`: Pool is operational and usage is normal (<60%)
    * `DEGRADED`: Pool is operational but usage is high (60-90%) or metrics partially unavailable
    * `UNHEALTHY`: Pool usage is critical (>90%) or connection failures
    * `UNKNOWN`: Metrics unavailable but client appears operational
* **Rule:** Only mark as `UNHEALTHY` for critical issues. Missing detailed metrics should be `UNKNOWN` or `DEGRADED`.

```python
from enum import Enum

class HealthStatus(Enum):
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"
    UNKNOWN = "unknown"

async def check_pool_health(get_metrics_func: Callable) -> HealthCheckResult:
    """Check connection pool health with proper status classification."""
    metrics = await get_metrics_func()
    status_value = metrics.get("status")
    
    if status_value != "connected":
        # Missing metrics but client might still work - use UNKNOWN
        if status_value in ["no_client", "error"]:
            return HealthCheckResult(
                name="connection_pool",
                status=HealthStatus.UNKNOWN,
                message="Pool metrics unavailable (client may still be operational)",
                details=metrics,
            )
        # Actual connection failure
        return HealthCheckResult(
            name="connection_pool",
            status=HealthStatus.UNHEALTHY,
            message=f"Pool status: {status_value}",
            details=metrics,
        )
    
    # Check usage percentage
    usage = metrics.get("pool_usage_percent")
    if usage is None:
        # Connected but no usage data - still healthy
        return HealthCheckResult(
            name="connection_pool",
            status=HealthStatus.HEALTHY,
            message="Connected (detailed metrics unavailable)",
            details=metrics,
        )
    
    if usage > 90:
        status = HealthStatus.UNHEALTHY
        message = f"Pool usage critical: {usage}%"
    elif usage > 60:
        status = HealthStatus.DEGRADED
        message = f"Pool usage high: {usage}%"
    else:
        status = HealthStatus.HEALTHY
        message = f"Pool usage normal: {usage}%"
    
    return HealthCheckResult(
        name="connection_pool",
        status=status,
        message=message,
        details=metrics,
    )
```

### E. Connection Pool Event Monitoring (Advanced)

* **Rule:** Motor/PyMongo's `ConnectionPoolListener` callbacks are **synchronous** and execute on the main thread/event loop. Keep them extremely lightweight to avoid blocking.
* **Rule:** For async apps, use `serverStatus` polling instead of event listeners for metrics collection.
* **Anti-Pattern:** Heavy operations (file I/O, API calls, complex calculations) in listener callbacks will freeze your async event loop.

```python
from pymongo.monitoring import ConnectionPoolListener

# ⚠️ Warning: These callbacks are SYNCHRONOUS and block the event loop
class PoolLogger(ConnectionPoolListener):
    def connection_checked_out(self, event):
        # ✅ OK: Lightweight logging
        logger.debug(f"Connection checked out: {event.connection_id}")
        
        # ❌ BAD: Heavy operations block the loop
        # requests.post("https://api.metrics.com", data=...)  # BLOCKS!
        # time.sleep(0.1)  # BLOCKS!
    
    def connection_checked_in(self, event):
        logger.debug(f"Connection checked in: {event.connection_id}")

# For production monitoring, prefer serverStatus polling instead
async def monitor_pool_periodically(client, interval=30):
    """Poll serverStatus for metrics instead of using listeners."""
    while True:
        metrics = await get_pool_metrics(client)
        # Send to metrics service (async, non-blocking)
        await send_to_metrics_service(metrics)
        await asyncio.sleep(interval)
```

### F. Common Pitfalls & Solutions

1. **"Pool metrics unavailable" in health checks:**
   * *Problem:* Health check queries shared client, but runtime engine uses its own client.
   * *Solution:* Register the engine's client using `register_client_for_metrics()`.

2. **High pool usage warnings:**
   * *Problem:* `maxPoolSize` too low for application concurrency.
   * *Solution:* Increase `maxPoolSize` or implement request queuing/throttling.

3. **Connection exhaustion:**
   * *Problem:* Not closing cursors, long-running transactions, or leaks.
   * *Solution:* Use context managers, set timeouts, monitor `total_connections_created` for leaks.

4. **Template errors accessing pool metrics:**
   * *Problem:* Direct attribute access (`pool_metrics.pool_usage_percent`) fails if key missing.
   * *Solution:* Use safe access patterns (`.get()` method) in templates and code.

```python
# ❌ Bad: Direct attribute access
if pool_metrics.pool_usage_percent > 80:  # KeyError if missing

# ✅ Good: Safe access
if pool_metrics.get('pool_usage_percent', 0) > 80:
```

## 3\. Robust Index Management (Atlas Search & Vector)

**Context:** Unlike standard B-tree indexes, Atlas Search (Vector/Lucene) indexes are built asynchronously on the cloud side. The API command returns *immediately*, but the index is not ready for query execution until the build finishes.

### A. Programmatic Definition (SearchIndexModel)

  * **Rule:** Define index configurations programmatically using typed models (e.g., `pymongo.operations.SearchIndexModel`) rather than raw dictionaries or manual UI creation. This ensures infrastructure-as-code.
  * **Rule:** Explicitly specify the index `type` (`vectorSearch` or `search`) and `name`.
  * **Best Practice:** For Vector Search, always index "filter" fields to allow for efficient pre-filtering.

<!-- end list -->

```python
from pymongo.operations import SearchIndexModel

# Example: Vector Search Index Definition
vector_model = SearchIndexModel(
    definition={
        "fields": [
            {
                "type": "vector",
                "path": "embedding",
                "numDimensions": 1536,
                "similarity": "cosine"
            },
            # Optimize: Index fields used in filters!
            {"type": "filter", "path": "category"},
            {"type": "filter", "path": "user_id"}
        ]
    },
    name="vector_index",
    type="vectorSearch"
)

# Example: Full-Text Search Index Definition
text_model = SearchIndexModel(
    definition={
        "mappings": {
            "dynamic": False,
            "fields": {
                "title": {"type": "string"},
                "description": {"type": "string"}
            }
        }
    },
    name="text_search_index",
    type="search"
)
```

### B. The "Wait for Ready" Pattern

  * **Rule:** Code that depends on an index immediately after creation (e.g., app startup, integration tests) **MUST** implement a polling mechanism.
  * **Logic:**
    1.  Submit `create_search_index`.
    2.  Poll `$listSearchIndexes` periodically.
    3.  **Crucial Check:** Wait until `queryable == true` AND `status == "READY"`.
    4.  Timeout gracefully if it takes too long.

<!-- end list -->

```python
import asyncio
import time

# Implementation Logic (Generic Async)
async def wait_for_search_index(collection, index_name: str, timeout: int = 300):
    """
    Polls the collection until the specified search index is queryable.
    """
    start = time.time()
    while time.time() - start < timeout:
        # Fetch status via aggregation
        cursor = collection.aggregate([{"$listSearchIndexes": {"name": index_name}}])
        
        # Cursor might be empty initially if index creation just started
        # We use a flag to track if we found the index in the list
        found = False
        async for index_info in cursor:
            found = True
            # Check both status and queryable flag
            if index_info.get("queryable") is True and index_info.get("status") == "READY":
                return True
            elif index_info.get("status") == "FAILED":
                raise Exception(f"Index build failed: {index_info}")
        
        # Wait before retrying
        await asyncio.sleep(5)
    
    raise TimeoutError(f"Index {index_name} not ready within {timeout} seconds.")
```

### C. Idempotency & Creation Logic

  * **Rule:** Index creation scripts must be **idempotent**.
  * **Rule:** Handle `OperationFailure` specifically for race conditions (e.g., "IndexAlreadyExists").
  * **Pattern:** The "Check-Compare-Act" loop.

<!-- end list -->

```python
from pymongo.errors import OperationFailure

async def ensure_index(collection, model):
    try:
        # 1. Attempt creation
        await collection.create_search_index(model=model)
        print(f"Creation initiated for index: {model.name}")
    except OperationFailure as e:
        # 2. Handle benign race conditions
        if "IndexAlreadyExists" in str(e) or "DuplicateIndexName" in str(e):
             # Optional: Check if definition changed and update if necessary
             # await collection.update_search_index(name=model.name, definition=model.definition)
             print(f"Index {model.name} already exists. Proceeding.")
        else:
            raise e
    
    # 3. Always wait for it to be ready before proceeding
    print(f"Waiting for index {model.name} to be queryable...")
    await wait_for_search_index(collection, model.name)
    print(f"Index {model.name} is ready.")
```

## 4\. Aggregation Pipeline Optimization

**Context:** The order of operations in MongoDB aggregation pipelines significantly impacts performance, especially with Vector Search.

  * **Rule (Ordering):** Specialized operators like `$vectorSearch`, `$search`, and `$geoNear` **MUST** be the very first stage in the pipeline.
  * **Rule (Pre-filtering):** Do not use a separate `$match` stage immediately after `$vectorSearch` to filter results.
      * *Why:* This forces the vector engine to scan irrelevant vectors (ANN search), only to discard them later.
      * *Fix:* Use the dedicated `filter` property *inside* the `$vectorSearch` definition.

<!-- end list -->

```javascript
// ✅ Correct: Filter INSIDE vectorSearch
{
  "$vectorSearch": {
    "index": "vector_index",
    "path": "embedding",
    "queryVector": [...],
    "filter": { "category": "books" } // Efficient pre-filtering
  }
}

// ⚠️ Incorrect: Match AFTER vectorSearch
// Scans "movies" vectors needlessly, then throws them away
[
  { "$vectorSearch": { ... } },
  { "$match": { "category": "books" } }
]
```

## 5\. General Implementation Guidelines

### Error Handling

  * **Rule:** Wrap administrative commands (create/drop/update) in `try/except` blocks to handle benign errors.
  * **Targeted Exceptions:**
      * `NamespaceNotFound`: Attempting to drop an index that doesn't exist.
      * `CollectionInvalid`: Attempting to create a collection that already exists.
      * `OperationFailure`: General Atlas errors (check error code/message).

### Scoping & Wrapping

  * **Pattern:** Use a wrapper or repository pattern to inject standard filters (e.g., `tenant_id`, `experiment_id`) automatically.
  * **Rule:** If using a wrapper, ensure it exposes the underlying driver objects (e.g., `database` or `collection`) for advanced operations like index management that should not be scoped.

## 6\. Anti-Patterns to Avoid

1.  **Fire-and-Forget Indexing:** Calling `create_search_index` and immediately running a query.
2.  **Assuming "READY" = Queryable:** In rare cases (updates/swaps), an index may report `READY` while the old version is still active. Always check `queryable: true`.
3.  **Blocking the Loop:** Using `pymongo` (sync) methods inside `async def` (Python) or `await` (Node) blocks.
4.  **Silent Failures:** Swallowing all exceptions during index creation. Always log the failure or raise a visible error.
5.  **Ignoring Pool Metrics:** Not monitoring connection pool usage leads to silent degradation and connection exhaustion.
6.  **Heavy Listener Callbacks:** Putting blocking operations in `ConnectionPoolListener` callbacks freezes async event loops.
7.  **Unregistered Clients:** Runtime engines with dedicated clients must register them for monitoring, or health checks will fail.
8.  **Over-Aggressive Health Checks:** Marking missing metrics as `UNHEALTHY` when the client is actually operational causes false alarms.